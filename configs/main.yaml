# Configurations for MyModel (encoder.py)
model:
  tau_initial: 0.5 # Initial value for tau
  vit: "google/vit-base-patch16-224" # Pre-trained ViT model
  clip_model_name: "openai/clip-vit-base-patch32" # Pre-trained CLIP model
  max_length: 77 # Maximum sequence length for token generation
  hard: False # Use hard sampling in gumbel softmax
  dim: -1 # Dimension for operations in MyModel

# Training configurations (train_model.py)
training:
  learning_rate: 0.001 # Learning rate for optimizer
  batch_size: 64 # Batch size for data loading
  num_epochs: 10 # Number of training epochs
  pre_trained_diffusion_model: "CompVis/stable-diffusion-v1-4" # Pre-trained diffusion model
  resize_dataloader: 256 # Resize parameter for DataLoader
  generate_image_model: "path/to/generate/image/model" # Model path for image generation

# Dataset configurations
dataset:
  cifar10_path: "/path/to/cifar10/dataset"
  image_url: "http://path.to.image/url" # If applicable

# Model saving configurations
model_checkpoint:
  path: "/path/to/save/model/checkpoints"
  filename: "model_checkpoints.pth"

# Logging and Visualization
logging:
  log_dir: "/path/to/log/directory"
